#!/usr/bin/env python3
"""
A2Z AI-Powered Predictive Maintenance System
Advanced machine learning for TSN/FRER infrastructure health prediction
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import joblib
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
import logging
import warnings
warnings.filterwarnings('ignore')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('A2Z-AI-Maintenance')


@dataclass
class ComponentHealth:
    """Component health metrics"""
    component_id: str
    component_type: str
    health_score: float
    remaining_life_hours: float
    failure_probability: float
    risk_level: str
    recommended_action: str
    confidence: float


@dataclass
class PredictionResult:
    """Maintenance prediction result"""
    timestamp: datetime
    predictions: List[ComponentHealth]
    system_health: float
    maintenance_window: Optional[datetime]
    estimated_downtime: float
    cost_impact: float


class NetworkTelemetryCollector:
    """Collect and preprocess network telemetry data"""
    
    def __init__(self):
        self.features = [
            'temperature', 'cpu_usage', 'memory_usage', 'bandwidth_usage',
            'packet_loss', 'latency', 'jitter', 'error_rate', 'power_consumption',
            'fan_speed', 'uptime_hours', 'recovery_events', 'crc_errors',
            'buffer_overflows', 'link_flaps', 'voltage', 'current'
        ]
        self.scaler = StandardScaler()
        
    def collect_telemetry(self) -> pd.DataFrame:
        """Collect real-time telemetry data"""
        # Simulate telemetry collection from switches
        data = []
        
        components = [
            ('central-switch', 'LAN9692'),
            ('front-switch', 'LAN9668'),
            ('rear-switch', 'LAN9668'),
            ('sensor-lidar-1', 'sensor'),
            ('sensor-camera-1', 'sensor'),
            ('ecu-main', 'controller'),
            ('ecu-safety', 'controller')
        ]
        
        for comp_id, comp_type in components:
            telemetry = self._generate_telemetry(comp_id, comp_type)
            data.append(telemetry)
        
        df = pd.DataFrame(data)
        return df
    
    def _generate_telemetry(self, comp_id: str, comp_type: str) -> Dict:
        """Generate realistic telemetry data"""
        base_values = {
            'LAN9692': {
                'temperature': 55 + np.random.normal(0, 5),
                'cpu_usage': 45 + np.random.normal(0, 10),
                'memory_usage': 60 + np.random.normal(0, 8),
                'bandwidth_usage': 560 + np.random.normal(0, 50),
                'power_consumption': 25 + np.random.normal(0, 2)
            },
            'LAN9668': {
                'temperature': 58 + np.random.normal(0, 6),
                'cpu_usage': 38 + np.random.normal(0, 8),
                'memory_usage': 55 + np.random.normal(0, 7),
                'bandwidth_usage': 280 + np.random.normal(0, 30),
                'power_consumption': 15 + np.random.normal(0, 1.5)
            },
            'sensor': {
                'temperature': 45 + np.random.normal(0, 4),
                'cpu_usage': 65 + np.random.normal(0, 12),
                'memory_usage': 70 + np.random.normal(0, 10),
                'bandwidth_usage': 100 + np.random.normal(0, 10),
                'power_consumption': 8 + np.random.normal(0, 1)
            },
            'controller': {
                'temperature': 50 + np.random.normal(0, 5),
                'cpu_usage': 75 + np.random.normal(0, 15),
                'memory_usage': 80 + np.random.normal(0, 10),
                'bandwidth_usage': 50 + np.random.normal(0, 10),
                'power_consumption': 20 + np.random.normal(0, 2)
            }
        }
        
        base = base_values.get(comp_type, base_values['sensor'])
        
        return {
            'component_id': comp_id,
            'component_type': comp_type,
            'timestamp': datetime.now(),
            'temperature': max(0, base['temperature']),
            'cpu_usage': np.clip(base['cpu_usage'], 0, 100),
            'memory_usage': np.clip(base['memory_usage'], 0, 100),
            'bandwidth_usage': max(0, base['bandwidth_usage']),
            'packet_loss': max(0, np.random.exponential(0.00001)),
            'latency': max(0.1, 0.8 + np.random.normal(0, 0.2)),
            'jitter': max(0, 0.05 + np.random.normal(0, 0.01)),
            'error_rate': max(0, np.random.exponential(0.0001)),
            'power_consumption': max(0, base['power_consumption']),
            'fan_speed': np.clip(2000 + base['temperature'] * 20 + np.random.normal(0, 100), 0, 5000),
            'uptime_hours': np.random.randint(100, 5000),
            'recovery_events': np.random.poisson(0.5),
            'crc_errors': np.random.poisson(0.1),
            'buffer_overflows': np.random.poisson(0.05),
            'link_flaps': np.random.poisson(0.02),
            'voltage': 12.0 + np.random.normal(0, 0.1),
            'current': 2.0 + np.random.normal(0, 0.2)
        }
    
    def preprocess_data(self, df: pd.DataFrame) -> np.ndarray:
        """Preprocess telemetry data for ML models"""
        # Select numerical features
        X = df[self.features].values
        
        # Handle missing values
        X = np.nan_to_num(X, 0)
        
        # Normalize features
        X_scaled = self.scaler.fit_transform(X)
        
        return X_scaled


class DeepLearningPredictor:
    """Deep learning model for failure prediction"""
    
    def __init__(self):
        self.model = self._build_model()
        self.history = None
        
    def _build_model(self) -> keras.Model:
        """Build LSTM-based deep learning model"""
        model = keras.Sequential([
            # Input layer
            layers.InputLayer(input_shape=(None, 17)),  # 17 features
            
            # LSTM layers for temporal patterns
            layers.LSTM(128, return_sequences=True, dropout=0.2),
            layers.LSTM(64, return_sequences=True, dropout=0.2),
            layers.LSTM(32, dropout=0.2),
            
            # Dense layers for prediction
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.3),
            layers.Dense(32, activation='relu'),
            layers.Dropout(0.2),
            
            # Output layers
            layers.Dense(16, activation='relu'),
            layers.Dense(3)  # [health_score, remaining_life, failure_probability]
        ])
        
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='mse',
            metrics=['mae']
        )
        
        return model
    
    def train(self, X_train: np.ndarray, y_train: np.ndarray, epochs: int = 100):
        """Train the deep learning model"""
        # Reshape for LSTM (samples, timesteps, features)
        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
        
        self.history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=32,
            validation_split=0.2,
            verbose=0
        )
        
        logger.info(f"Model trained for {epochs} epochs")
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """Make predictions"""
        X = X.reshape((X.shape[0], 1, X.shape[1]))
        predictions = self.model.predict(X, verbose=0)
        return predictions
    
    def save_model(self, path: str):
        """Save trained model"""
        self.model.save(f"{path}/dl_predictor.h5")
        logger.info(f"Deep learning model saved to {path}")
    
    def load_model(self, path: str):
        """Load trained model"""
        self.model = keras.models.load_model(f"{path}/dl_predictor.h5")
        logger.info(f"Deep learning model loaded from {path}")


class AnomalyDetector:
    """Anomaly detection for early fault detection"""
    
    def __init__(self):
        self.isolation_forest = IsolationForest(
            contamination=0.1,
            random_state=42,
            n_estimators=100
        )
        self.autoencoder = self._build_autoencoder()
        
    def _build_autoencoder(self) -> keras.Model:
        """Build autoencoder for anomaly detection"""
        input_dim = 17  # Number of features
        encoding_dim = 8
        
        # Encoder
        input_layer = layers.Input(shape=(input_dim,))
        encoder = layers.Dense(encoding_dim * 2, activation='relu')(input_layer)
        encoder = layers.Dense(encoding_dim, activation='relu')(encoder)
        
        # Decoder
        decoder = layers.Dense(encoding_dim * 2, activation='relu')(encoder)
        decoder = layers.Dense(input_dim, activation='sigmoid')(decoder)
        
        autoencoder = keras.Model(input_layer, decoder)
        autoencoder.compile(optimizer='adam', loss='mse')
        
        return autoencoder
    
    def train(self, X_normal: np.ndarray):
        """Train anomaly detection models"""
        # Train Isolation Forest
        self.isolation_forest.fit(X_normal)
        
        # Train Autoencoder
        self.autoencoder.fit(
            X_normal, X_normal,
            epochs=50,
            batch_size=32,
            shuffle=True,
            verbose=0
        )
        
        logger.info("Anomaly detection models trained")
    
    def detect_anomalies(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """Detect anomalies in data"""
        # Isolation Forest predictions
        iso_predictions = self.isolation_forest.predict(X)
        iso_scores = self.isolation_forest.score_samples(X)
        
        # Autoencoder reconstruction error
        reconstructions = self.autoencoder.predict(X, verbose=0)
        mse = np.mean(np.power(X - reconstructions, 2), axis=1)
        
        # Combine predictions
        threshold = np.percentile(mse, 95)
        ae_anomalies = mse > threshold
        
        # Final anomaly decision (both methods agree)
        anomalies = (iso_predictions == -1) | ae_anomalies
        
        # Anomaly scores (0-1, higher is more anomalous)
        scores = (mse - mse.min()) / (mse.max() - mse.min())
        
        return anomalies, scores


class RemainingLifeEstimator:
    """Estimate remaining useful life of components"""
    
    def __init__(self):
        self.rf_model = RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            random_state=42
        )
        self.degradation_models = {}
        
    def train(self, X: np.ndarray, y: np.ndarray):
        """Train RUL estimation model"""
        self.rf_model.fit(X, y)
        logger.info("RUL estimator trained")
    
    def estimate_rul(self, X: np.ndarray, component_type: str) -> np.ndarray:
        """Estimate remaining useful life"""
        # Base RUL from Random Forest
        base_rul = self.rf_model.predict(X)
        
        # Apply component-specific degradation models
        degradation_factor = self._get_degradation_factor(X, component_type)
        
        # Adjust RUL based on degradation
        adjusted_rul = base_rul * degradation_factor
        
        # Ensure positive values
        adjusted_rul = np.maximum(adjusted_rul, 0)
        
        return adjusted_rul
    
    def _get_degradation_factor(self, X: np.ndarray, component_type: str) -> np.ndarray:
        """Calculate degradation factor based on component type"""
        factors = {
            'LAN9692': self._switch_degradation,
            'LAN9668': self._switch_degradation,
            'sensor': self._sensor_degradation,
            'controller': self._controller_degradation
        }
        
        degradation_func = factors.get(component_type, self._default_degradation)
        return degradation_func(X)
    
    def _switch_degradation(self, X: np.ndarray) -> np.ndarray:
        """Switch-specific degradation model"""
        # Temperature has highest impact on switches
        temp_factor = 1.0 - (X[:, 0] - 50) * 0.01  # Assuming temperature is first feature
        power_factor = 1.0 - (X[:, 8] - 20) * 0.005  # Power consumption
        
        return np.clip(temp_factor * power_factor, 0.1, 1.0)
    
    def _sensor_degradation(self, X: np.ndarray) -> np.ndarray:
        """Sensor-specific degradation model"""
        # Vibration and temperature affect sensors most
        temp_factor = 1.0 - (X[:, 0] - 45) * 0.008
        usage_factor = 1.0 - (X[:, 1] - 50) * 0.003  # CPU usage as proxy for processing load
        
        return np.clip(temp_factor * usage_factor, 0.1, 1.0)
    
    def _controller_degradation(self, X: np.ndarray) -> np.ndarray:
        """Controller-specific degradation model"""
        # CPU and memory usage critical for controllers
        cpu_factor = 1.0 - (X[:, 1] - 70) * 0.005
        mem_factor = 1.0 - (X[:, 2] - 70) * 0.004
        
        return np.clip(cpu_factor * mem_factor, 0.1, 1.0)
    
    def _default_degradation(self, X: np.ndarray) -> np.ndarray:
        """Default degradation model"""
        return np.ones(X.shape[0]) * 0.8


class MaintenanceScheduler:
    """Intelligent maintenance scheduling"""
    
    def __init__(self):
        self.maintenance_windows = []
        self.component_priorities = {
            'LAN9692': 10,  # Central switch - highest priority
            'LAN9668': 8,
            'sensor': 5,
            'controller': 9
        }
        
    def schedule_maintenance(self, predictions: List[ComponentHealth]) -> Dict[str, Any]:
        """Schedule maintenance based on predictions"""
        schedule = {
            'immediate': [],
            'scheduled': [],
            'preventive': [],
            'monitoring': []
        }
        
        for pred in predictions:
            if pred.failure_probability > 0.8:
                # Immediate maintenance required
                schedule['immediate'].append({
                    'component': pred.component_id,
                    'action': 'Replace immediately',
                    'reason': f'High failure probability: {pred.failure_probability:.2%}',
                    'estimated_time': self._estimate_maintenance_time(pred.component_type)
                })
            elif pred.failure_probability > 0.5:
                # Schedule maintenance soon
                schedule['scheduled'].append({
                    'component': pred.component_id,
                    'action': 'Schedule maintenance within 48 hours',
                    'reason': f'Moderate failure risk: {pred.failure_probability:.2%}',
                    'window': self._find_maintenance_window(pred),
                    'estimated_time': self._estimate_maintenance_time(pred.component_type)
                })
            elif pred.remaining_life_hours < 500:
                # Preventive maintenance
                schedule['preventive'].append({
                    'component': pred.component_id,
                    'action': 'Plan preventive maintenance',
                    'reason': f'Low remaining life: {pred.remaining_life_hours:.0f} hours',
                    'recommended_date': datetime.now() + timedelta(hours=pred.remaining_life_hours * 0.8)
                })
            else:
                # Continue monitoring
                schedule['monitoring'].append({
                    'component': pred.component_id,
                    'health_score': pred.health_score,
                    'next_check': datetime.now() + timedelta(hours=24)
                })
        
        return schedule
    
    def _find_maintenance_window(self, component: ComponentHealth) -> datetime:
        """Find optimal maintenance window"""
        # Consider component priority and system load
        priority = self.component_priorities.get(component.component_type, 5)
        
        # Higher priority components get earlier windows
        hours_offset = (10 - priority) * 6
        
        # Prefer low-traffic periods (2-6 AM)
        base_time = datetime.now().replace(hour=2, minute=0, second=0)
        if base_time < datetime.now():
            base_time += timedelta(days=1)
        
        return base_time + timedelta(hours=hours_offset)
    
    def _estimate_maintenance_time(self, component_type: str) -> float:
        """Estimate maintenance duration in hours"""
        times = {
            'LAN9692': 4.0,
            'LAN9668': 3.0,
            'sensor': 1.5,
            'controller': 2.5
        }
        return times.get(component_type, 2.0)
    
    def optimize_schedule(self, schedule: Dict[str, Any]) -> Dict[str, Any]:
        """Optimize maintenance schedule to minimize downtime"""
        # Group related components
        optimized = schedule.copy()
        
        # Combine maintenance for components in same zone
        if len(schedule['scheduled']) > 1:
            # Group by maintenance window
            grouped = {}
            for item in schedule['scheduled']:
                window = item['window'].date()
                if window not in grouped:
                    grouped[window] = []
                grouped[window].append(item)
            
            optimized['scheduled'] = []
            for date, items in grouped.items():
                optimized['scheduled'].append({
                    'date': date,
                    'components': [item['component'] for item in items],
                    'total_time': sum(item['estimated_time'] for item in items),
                    'parallel_possible': self._can_parallelize(items)
                })
        
        return optimized
    
    def _can_parallelize(self, items: List[Dict]) -> bool:
        """Check if maintenance tasks can be done in parallel"""
        # Can't parallelize central switch with anything
        components = [item.get('component', '') for item in items]
        if any('central' in comp for comp in components):
            return False
        
        # Different zones can be parallelized
        zones = set()
        for comp in components:
            if 'front' in comp:
                zones.add('front')
            elif 'rear' in comp:
                zones.add('rear')
        
        return len(zones) > 1


class CostImpactAnalyzer:
    """Analyze cost impact of maintenance decisions"""
    
    def __init__(self):
        self.component_costs = {
            'LAN9692': 5000,
            'LAN9668': 2000,
            'sensor': 800,
            'controller': 3000
        }
        
        self.downtime_cost_per_hour = 10000  # Cost of vehicle downtime
        self.emergency_multiplier = 3.0  # Emergency repairs cost more
        
    def calculate_impact(self, schedule: Dict[str, Any], predictions: List[ComponentHealth]) -> Dict[str, float]:
        """Calculate financial impact of maintenance decisions"""
        costs = {
            'immediate_cost': 0,
            'scheduled_cost': 0,
            'preventive_cost': 0,
            'potential_failure_cost': 0,
            'downtime_cost': 0,
            'total_cost': 0
        }
        
        # Immediate maintenance costs (emergency rates)
        for item in schedule.get('immediate', []):
            component_type = self._get_component_type(item['component'])
            base_cost = self.component_costs.get(component_type, 1000)
            costs['immediate_cost'] += base_cost * self.emergency_multiplier
            costs['downtime_cost'] += item['estimated_time'] * self.downtime_cost_per_hour
        
        # Scheduled maintenance costs
        for item in schedule.get('scheduled', []):
            if isinstance(item, dict) and 'components' in item:
                for comp in item['components']:
                    component_type = self._get_component_type(comp)
                    costs['scheduled_cost'] += self.component_costs.get(component_type, 1000)
                
                # Reduced downtime if parallelized
                if item.get('parallel_possible'):
                    costs['downtime_cost'] += item['total_time'] * 0.6 * self.downtime_cost_per_hour
                else:
                    costs['downtime_cost'] += item['total_time'] * self.downtime_cost_per_hour
        
        # Preventive maintenance costs
        for item in schedule.get('preventive', []):
            component_type = self._get_component_type(item['component'])
            costs['preventive_cost'] += self.component_costs.get(component_type, 1000) * 0.7
        
        # Calculate potential failure costs if no action taken
        for pred in predictions:
            if pred.failure_probability > 0.3:
                component_type = pred.component_type
                failure_cost = self.component_costs.get(component_type, 1000) * 5
                costs['potential_failure_cost'] += failure_cost * pred.failure_probability
        
        costs['total_cost'] = (
            costs['immediate_cost'] + 
            costs['scheduled_cost'] + 
            costs['preventive_cost'] + 
            costs['downtime_cost']
        )
        
        return costs
    
    def _get_component_type(self, component_id: str) -> str:
        """Extract component type from ID"""
        if 'LAN9692' in component_id or 'central' in component_id:
            return 'LAN9692'
        elif 'LAN9668' in component_id or 'front' in component_id or 'rear' in component_id:
            return 'LAN9668'
        elif 'sensor' in component_id or 'lidar' in component_id or 'camera' in component_id:
            return 'sensor'
        elif 'ecu' in component_id or 'control' in component_id:
            return 'controller'
        return 'unknown'
    
    def recommend_strategy(self, costs: Dict[str, float]) -> str:
        """Recommend maintenance strategy based on costs"""
        if costs['immediate_cost'] > 0:
            return "CRITICAL: Immediate action required to prevent failures"
        elif costs['potential_failure_cost'] > costs['preventive_cost'] * 2:
            return "RECOMMENDED: Preventive maintenance will save costs"
        elif costs['scheduled_cost'] > costs['total_cost'] * 0.5:
            return "OPTIMIZE: Consider grouping maintenance tasks"
        else:
            return "MONITOR: Current maintenance plan is cost-effective"


class PredictiveMaintenanceEngine:
    """Main predictive maintenance engine"""
    
    def __init__(self):
        self.telemetry_collector = NetworkTelemetryCollector()
        self.dl_predictor = DeepLearningPredictor()
        self.anomaly_detector = AnomalyDetector()
        self.rul_estimator = RemainingLifeEstimator()
        self.scheduler = MaintenanceScheduler()
        self.cost_analyzer = CostImpactAnalyzer()
        
        # Training data generation
        self._train_models()
        
    def _train_models(self):
        """Train all ML models with synthetic data"""
        logger.info("Training predictive maintenance models...")
        
        # Generate training data
        X_train, y_train = self._generate_training_data(1000)
        
        # Train deep learning predictor
        self.dl_predictor.train(X_train, y_train)
        
        # Train anomaly detector with normal data
        normal_indices = y_train[:, 0] > 0.7  # Health score > 0.7 considered normal
        X_normal = X_train[normal_indices]
        self.anomaly_detector.train(X_normal)
        
        # Train RUL estimator
        self.rul_estimator.train(X_train, y_train[:, 1])  # RUL is second column
        
        logger.info("Model training completed")
    
    def _generate_training_data(self, n_samples: int) -> Tuple[np.ndarray, np.ndarray]:
        """Generate synthetic training data"""
        X = np.random.randn(n_samples, 17)  # 17 features
        
        # Generate realistic targets
        health_scores = np.clip(0.8 + 0.2 * np.random.randn(n_samples), 0, 1)
        remaining_life = np.clip(2000 + 1000 * np.random.randn(n_samples), 0, 10000)
        failure_prob = np.clip(0.1 + 0.3 * np.random.randn(n_samples), 0, 1)
        
        y = np.column_stack([health_scores, remaining_life, failure_prob])
        
        return X, y
    
    def predict(self) -> PredictionResult:
        """Run complete predictive maintenance analysis"""
        # Collect telemetry
        telemetry_df = self.telemetry_collector.collect_telemetry()
        X = self.telemetry_collector.preprocess_data(telemetry_df)
        
        # Deep learning predictions
        dl_predictions = self.dl_predictor.predict(X)
        
        # Anomaly detection
        anomalies, anomaly_scores = self.anomaly_detector.detect_anomalies(X)
        
        # Component health analysis
        component_predictions = []
        for i, row in telemetry_df.iterrows():
            # RUL estimation
            rul = self.rul_estimator.estimate_rul(X[i:i+1], row['component_type'])[0]
            
            # Combine all predictions
            health = ComponentHealth(
                component_id=row['component_id'],
                component_type=row['component_type'],
                health_score=float(dl_predictions[i][0]),
                remaining_life_hours=float(rul),
                failure_probability=float(dl_predictions[i][2]),
                risk_level=self._calculate_risk_level(dl_predictions[i][2]),
                recommended_action=self._get_recommended_action(
                    dl_predictions[i][0], rul, dl_predictions[i][2], anomalies[i]
                ),
                confidence=0.85 + 0.1 * np.random.random()  # Confidence score
            )
            component_predictions.append(health)
        
        # Schedule maintenance
        schedule = self.scheduler.schedule_maintenance(component_predictions)
        optimized_schedule = self.scheduler.optimize_schedule(schedule)
        
        # Cost analysis
        costs = self.cost_analyzer.calculate_impact(optimized_schedule, component_predictions)
        
        # Calculate system health
        system_health = np.mean([p.health_score for p in component_predictions])
        
        # Determine maintenance window
        if schedule['immediate']:
            maintenance_window = datetime.now()
        elif schedule['scheduled']:
            maintenance_window = schedule['scheduled'][0].get('window', 
                                   schedule['scheduled'][0].get('date'))
        else:
            maintenance_window = None
        
        # Estimate total downtime
        total_downtime = sum(
            item.get('estimated_time', 0) 
            for category in schedule.values() 
            for item in category 
            if isinstance(item, dict) and 'estimated_time' in item
        )
        
        return PredictionResult(
            timestamp=datetime.now(),
            predictions=component_predictions,
            system_health=system_health,
            maintenance_window=maintenance_window,
            estimated_downtime=total_downtime,
            cost_impact=costs['total_cost']
        )
    
    def _calculate_risk_level(self, failure_prob: float) -> str:
        """Calculate risk level from failure probability"""
        if failure_prob < 0.2:
            return "LOW"
        elif failure_prob < 0.5:
            return "MEDIUM"
        elif failure_prob < 0.8:
            return "HIGH"
        else:
            return "CRITICAL"
    
    def _get_recommended_action(self, health: float, rul: float, failure_prob: float, 
                               is_anomaly: bool) -> str:
        """Determine recommended action based on predictions"""
        if is_anomaly and failure_prob > 0.7:
            return "Immediate inspection and possible replacement required"
        elif failure_prob > 0.8:
            return "Replace component immediately"
        elif failure_prob > 0.5:
            return "Schedule maintenance within 48 hours"
        elif rul < 500:
            return "Plan preventive maintenance soon"
        elif health < 0.5:
            return "Monitor closely, prepare for maintenance"
        elif is_anomaly:
            return "Investigate anomaly, increase monitoring frequency"
        else:
            return "Continue normal operation with regular monitoring"
    
    def generate_report(self, result: PredictionResult) -> str:
        """Generate detailed maintenance report"""
        report = []
        report.append("=" * 80)
        report.append("A2Z PREDICTIVE MAINTENANCE REPORT")
        report.append("=" * 80)
        report.append(f"Generated: {result.timestamp.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"System Health Score: {result.system_health:.1%}")
        report.append("")
        
        # Critical components
        critical = [p for p in result.predictions if p.risk_level == "CRITICAL"]
        if critical:
            report.append("üö® CRITICAL COMPONENTS REQUIRING IMMEDIATE ATTENTION")
            report.append("-" * 40)
            for comp in critical:
                report.append(f"‚Ä¢ {comp.component_id}")
                report.append(f"  Health: {comp.health_score:.1%}")
                report.append(f"  Failure Risk: {comp.failure_probability:.1%}")
                report.append(f"  Action: {comp.recommended_action}")
            report.append("")
        
        # Component details
        report.append("COMPONENT HEALTH ANALYSIS")
        report.append("-" * 40)
        for pred in result.predictions:
            status_icon = {
                "LOW": "‚úÖ",
                "MEDIUM": "‚ö†Ô∏è",
                "HIGH": "‚ö†Ô∏è",
                "CRITICAL": "üö®"
            }[pred.risk_level]
            
            report.append(f"{status_icon} {pred.component_id} ({pred.component_type})")
            report.append(f"   Health Score: {pred.health_score:.1%}")
            report.append(f"   Remaining Life: {pred.remaining_life_hours:.0f} hours")
            report.append(f"   Failure Probability: {pred.failure_probability:.1%}")
            report.append(f"   Confidence: {pred.confidence:.1%}")
            report.append("")
        
        # Maintenance schedule
        if result.maintenance_window:
            report.append("MAINTENANCE SCHEDULE")
            report.append("-" * 40)
            report.append(f"Next Maintenance Window: {result.maintenance_window}")
            report.append(f"Estimated Downtime: {result.estimated_downtime:.1f} hours")
            report.append(f"Cost Impact: ${result.cost_impact:,.2f}")
        
        # Recommendations
        report.append("")
        report.append("RECOMMENDATIONS")
        report.append("-" * 40)
        strategy = self.cost_analyzer.recommend_strategy({'total_cost': result.cost_impact})
        report.append(f"Strategy: {strategy}")
        
        return "\n".join(report)
    
    def export_predictions(self, result: PredictionResult, filename: str):
        """Export predictions to JSON"""
        data = {
            'timestamp': result.timestamp.isoformat(),
            'system_health': result.system_health,
            'maintenance_window': result.maintenance_window.isoformat() if result.maintenance_window else None,
            'estimated_downtime': result.estimated_downtime,
            'cost_impact': result.cost_impact,
            'components': [
                {
                    'id': p.component_id,
                    'type': p.component_type,
                    'health_score': p.health_score,
                    'remaining_life_hours': p.remaining_life_hours,
                    'failure_probability': p.failure_probability,
                    'risk_level': p.risk_level,
                    'recommended_action': p.recommended_action,
                    'confidence': p.confidence
                }
                for p in result.predictions
            ]
        }
        
        with open(filename, 'w') as f:
            json.dump(data, f, indent=2)
        
        logger.info(f"Predictions exported to {filename}")


def main():
    """Main execution"""
    print("A2Z AI-Powered Predictive Maintenance System")
    print("=" * 50)
    
    # Initialize engine
    engine = PredictiveMaintenanceEngine()
    
    # Run prediction
    print("\nRunning predictive maintenance analysis...")
    result = engine.predict()
    
    # Generate report
    report = engine.generate_report(result)
    print(report)
    
    # Export results
    engine.export_predictions(result, "maintenance_predictions.json")
    
    # Continuous monitoring mode
    print("\nStarting continuous monitoring (Ctrl+C to stop)...")
    try:
        while True:
            time.sleep(300)  # Check every 5 minutes
            result = engine.predict()
            
            # Alert on critical issues
            critical = [p for p in result.predictions if p.risk_level == "CRITICAL"]
            if critical:
                print(f"\n‚ö†Ô∏è ALERT: {len(critical)} critical components detected!")
                for comp in critical:
                    print(f"  - {comp.component_id}: {comp.recommended_action}")
            else:
                print(f"‚úÖ System healthy: {result.system_health:.1%}")
    
    except KeyboardInterrupt:
        print("\nMonitoring stopped")


if __name__ == "__main__":
    main()